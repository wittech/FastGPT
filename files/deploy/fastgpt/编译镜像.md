cd /data/FastGPT
git pull
docker build -t fastgpt --build-arg name=app --build-arg proxy=taobao .

cd /data/FastGPT/files/deploy/fastgpt
docker-compose down
docker-compose up -d

xinference launch -u miic_bge_m3 -n miic_bge_m3 -t embedding -e "http://127.0.0.1:8888"
--n-gpu None试试

xinference launch --model-name bge-m3 --model-type embedding
xinference launch --model-name bge-reranker-v2-m3 --model-type rerank

python3 -m pip install --upgrade pip
pip3 install "xinference[all]" -i https://pypi.tuna.tsinghua.edu.cn/simple/
XINFERENCE_MODEL_SRC=modelscope XINFERENCE_HOME=/root/autodl-tmp/xinference xinference-local --host 0.0.0.0 --port 6006